{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nS0rXcPFocr"
      },
      "outputs": [],
      "source": [
        "import numpy as np #needed for matrix algebra\n",
        "import pandas as pd #for data-frame dataframes are basically 2D arrays\n",
        "from matplotlib import pyplot as plt #for plotting the images\n",
        "\n",
        "data = pd.read_csv('/input/digit-recognizer/train.csv') #take the csv data and create a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)  #convert it into a numpy array\n",
        "m, n = data.shape #m = rows n = columns\n",
        "np.random.shuffle(data) # shuffle before splitting into dev and training sets\n",
        "\n",
        "data_dev = data[0:1000].T #take first 1000 rows and transpose them\n",
        "Y_dev = data_dev[0] #first row of the transposed one is all the labels\n",
        "X_dev = data_dev[1:n] #rest of the rows is the pixel\n",
        "X_dev = X_dev / 255. #normalizing the pixel values using float division\n",
        "\n",
        "data_train = data[1000:m].T #take rest of the rows m here is the total number of rows of the original dataset and transpose them\n",
        "Y_train = data_train[0] #take the labels row\n",
        "X_train = data_train[1:n] #take the rest of the rows\n",
        "X_train = X_train / 255.  #normalizing the pixel values using float division\n",
        "_,m_train = X_train.shape #aftar the transpose rows are pixel no and columns are no of examples so that is what m_train will store as shape returns rows, colum"
      ],
      "metadata": {
        "id": "sSA3-mzMFyVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(m_train)\n",
        "print(m,n) #42000 examples each row is a training example"
      ],
      "metadata": {
        "id": "UqsVBwNjFyka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "id": "2T91t-flF710"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params():\n",
        "    W1 = np.random.rand(10, 784) - 0.5 # the values generated are from [0,1) and this makes it [-0.5,0.5] also we do W*X so W being 10 x 784 and X being 784 by one it becomes 10x 1\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0) #self explanatory\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z)) #our Z is 10x1 so what it does is takes e^z for all elements of Z and divides it with sum of all e^z so we get softmaxed matrix\n",
        "    return A\n",
        "\n",
        "def forward_prop(W1, b1, W2, b2, X):\n",
        "    Z1 = W1.dot(X) + b1 #dot is matrix multiplication W1 is 10x784 and X is 784x1 so Z1 is 10x1\n",
        "    A1 = ReLU(Z1) #A1 is 10x1\n",
        "    Z2 = W2.dot(A1) + b2 #W2 is 10X10 and A1 is 10x 1 so Z2 is 10 x 1\n",
        "    A2 = softmax(Z2) #A2 is 10x 1\n",
        "    return Z1, A1, Z2, A2\n",
        "\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1)) #size is total number of element say shape gives us m,n then size gives us m*n  and other gives us maximum element+1 ie 9+1 so the shape is (number of labels,10)\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
        "    db2 = 1 / m * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
        "    dW1 = 1 / m * dZ1.dot(X.T)\n",
        "    db1 = 1 / m * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "lwgaB9oBF74w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2"
      ],
      "metadata": {
        "id": "EHYcyoBmF78A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
      ],
      "metadata": {
        "id": "i1sqhSfJF7-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(X, W1, b1, W2, b2):\n",
        "    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "    predictions = get_predictions(A2)\n",
        "    return predictions\n",
        "\n",
        "def test_prediction(index, W1, b1, W2, b2):\n",
        "    current_image = X_train[:, index, None]\n",
        "    prediction = make_predictions(X_train[:, index, None], W1, b1, W2, b2)\n",
        "    label = Y_train[index]\n",
        "    print(\"Prediction: \", prediction)\n",
        "    print(\"Label: \", label)\n",
        "\n",
        "    current_image = current_image.reshape((28, 28)) * 255\n",
        "    plt.gray()\n",
        "    plt.imshow(current_image, interpolation='nearest')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uBwO-iw2F8Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction(0, W1, b1, W2, b2)\n",
        "test_prediction(1, W1, b1, W2, b2)\n",
        "test_prediction(2, W1, b1, W2, b2)\n",
        "test_prediction(3, W1, b1, W2, b2)"
      ],
      "metadata": {
        "id": "vgLnoAY6F8E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_predictions = make_predictions(X_dev, W1, b1, W2, b2)\n",
        "get_accuracy(dev_predictions, Y_dev)"
      ],
      "metadata": {
        "id": "uB8nMEglF8IE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W3Xl-Tl1F8La"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gaOVNcZQF8OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hr-HRq4iF8Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qW5hNSY1F8Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czWsgU-EF8Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jN9unFvXF8a9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-wlkvjgrF8ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Q0HwTRGF8h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8t-BM2EcF8lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FALxeEeIF8oW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}